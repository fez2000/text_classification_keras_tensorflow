{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac316b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d6452c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#commentaire\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06f9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset(\"./datas/sms.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cd7edaf0-0c26-46f5-8f94-5adfdaf3a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "ham\tOk lar... Joking wif u oni...\n",
      "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "ham\tU dun say so early hor... U c already then say...\n",
      "ham\tNah I don't think he goes to usf, he lives around here though\n"
     ]
    }
   ],
   "source": [
    "for line in dataset.take(5):\n",
    "    print(line.numpy().decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5330bcc9-28ac-4a6c-ba59-47933f1e1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set();\n",
    "def getLabel(line):\n",
    "\n",
    "    parts = tf.strings.split(line,\"\\t\");\n",
    "    \n",
    "    return parts[1],parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "253350e9-1c4b-4cc2-83be-d5a2a6835f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spam', 'ham'}\n"
     ]
    }
   ],
   "source": [
    "#on melange les donnes puis on recupre les classes\n",
    "d2 = dataset.shuffle(buffer_size=100).map(getLabel);\n",
    "for i, lab in d2:\n",
    "    labels.add(lab.numpy().decode('UTF-8'))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1d82b5be-ca0e-4081-b3fe-2f5e13e0459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  train or test already exists\n",
      "Directory  spam  already exists\n",
      "Directory  spam  already exists\n",
      "Directory  ham  already exists\n",
      "Directory  ham  already exists\n"
     ]
    }
   ],
   "source": [
    "#creation des dossiers pour les donnees de test et d'entrainement\n",
    "try:\n",
    "    os.makedirs(\"./datas/train\")\n",
    "    os.makedirs(\"./datas/test\")\n",
    "except FileExistsError:\n",
    "    print(\"Directory  train or test already exists\")\n",
    "for label in labels:\n",
    "    try:\n",
    "        os.makedirs(\"./datas/train/{}\".format(label))\n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , label ,  \" already exists\") \n",
    "    try:\n",
    "        os.makedirs(\"./datas/test/{}\".format(label))\n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , label ,  \" already exists\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "49f2eab2-bf1d-4383-8806-4a7aae090517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5000067-cce2-43e1-8bb2-3bda2d2c76a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'configure_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bcc99a251622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# configuration des donnees pour plus de performances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mint_train_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigure_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_train_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mint_val_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigure_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_val_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mint_test_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigure_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_test_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'configure_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 250\n",
    "\n",
    "int_vectorize_layer = TextVectorization(output_mode='int')\n",
    "d_r = d2.take(4000)\n",
    "d_t = d2.skip(4000).take(1574)\n",
    "train_text = d_r.map(lambda text, labels: text)\n",
    "t_text = d_t.map(lambda text, labels: text)\n",
    "# configuration des donnees pour plus de performances \n",
    "int_train_ds = configure_dataset(int_train_ds)\n",
    "int_val_ds = configure_dataset(int_val_ds)\n",
    "int_test_ds = configure_dataset(int_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263281a6-6dbb-48fb-a543-bd4d4ca3f6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
